---
title: "Test"
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
set.seed(123)
library(learnr)
#library(mlr3tuning)
library(rchallenge)
library(mlr3)
#library(mlr3verse)
library(mlr3learners)
source("test_functions.R", local = knitr::knit_global())
tutorial_options(exercise.checker = checker_endpoint)
data("german", package = "rchallenge")
data("BostonHousing", package = "mlbench")

### needed for r example r chunks
taskRegr = as_task_regr(BostonHousing, id = "BostonHousing", target = "medv")
lrnRegr = lrn("regr.rpart")
lrnRegr$train(taskRegr)
lrnRegr$predict(taskRegr)

### needed for checks in backend
taskClassifSol = as_task_classif(german, id = "GermanCredit", target = "credit_risk")
lrnClassifSol = lrn("classif.log_reg")
lrnClassifSol$train(taskClassifSol)
lrnClassifSol$predict(taskClassifSol)

### needed for PE 
resampling = rsmp("holdout", ratio = 2/3)
resRegr = resample(taskRegr, learner = lrnRegr, resampling = resampling)
resClassSol = resample(taskClassifSol, learner = lrnClassifSol, resampling = resampling)
```

## The data {data-progressive=FALSE}
In this tutorial we will guide you through the basic components of mlr3. Therefore we have already loaded two well known 
datasets.

### German credit scoring data 
The German credit data was originally donated in 1994 by Prof. Dr. Hans Hoffman of the University of Hamburg. A description can be found at the UCI repository. The goal is to classify people by their credit risk (good or bad) using 20 personal, demographic and financial features
```{r}
data("german", package = "rchallenge")

str(german)
```

### Boston housing data
Housing data for 506 census tracts of Boston from the 1970 census. The dataframe BostonHousing contains the original data by Harrison and Rubinfeld (1979). In this use case, we want to build a model that predicts the Median value of owner-occupied homes in Boston in $1000â€™s (medv).
```{r}
data("BostonHousing", package = "mlbench")

str(BostonHousing)
```

## 1 Tasks
Tasks in mlr3 not only define our data backend, they also store meta-information about our data (e.g. which column is the target etc.). 

### 1.1 Defining a task
There are several ways to define a task in mlr3. We have already instantiated the Task for our regression problem:  
```{r}
taskRegr = as_task_regr(BostonHousing, id = "BostonHousing", target = "medv")
```

Now, we also want to define a task for our classification problem. Create a new Classification task using the as_task_classif method, the german credit scoring data set as backend and the column "credit_risk" as target. 

```{r task, exercise=TRUE}
taskClassif = "your code"
```

```{r task-check}
checker_endpoint()
```

```{r task-solution}
taskClassif = as_task_classif(german, id = "GermanCredit", target = "credit_risk")
```

## 2 Learner

### 2.1 Defining a learner
As with the task, we have already defined our learner for the regression problem. Now it's your turn, define a learner using logistic regression.   
```{r}
lrnRegr = lrn("regr.rpart")
```

```{r learner, exercise=TRUE}
lrnClassif = "Your code"
```

```{r learner-check}
checker_endpoint()
```

```{r learner-solution, exercise.setup = "task-solution"}
lrnClassif = lrn("classif.log_reg")
#taskClassif = as_task_classif(german, id = "GermanCredit", target = "credit_risk")
```
<div id="filter-hint">
**Hint:** Have a look at the learner defintions in mlr3: https://mlr3learners.mlr-org.com/.
</div>

### 2.2 Training a learner
Now it's time to train our learners and fit a model! We have already done the training of the regression learner. Now it's your turn to train the classification learner we have defined in the previous subtask!

```{r}
lrnRegr$train(taskRegr)
```

```{r train, exercise=TRUE, exercise.setup = "learner-solution"}
"your code"
```

```{r train-check}
checker_endpoint()
```

```{r train-solution}
lrnClassif$train(taskClassif)
```
<div id="filter-hint">
**Hint:** Think about the connection between learners and tasks. 
</div>

### 2.3 A look into the fitted model
Before we make any predictions, we are interested in information about our fitted model. This information can be accessed via the "$model"-call of a learner.
Lets' have a look into our regression model which fitted a regression tree:
```{r}
print(lrnRegr$model)
```
Look into the information of the fitted regression model and check all correct answers: 
```{r quiz_model, echo=FALSE}
question("How many terminal nodes does the fitted tree have?",
  answer("8", correct = TRUE),
  answer("14"),
  answer("12"),
  answer("5")
)
```
### 2.4 Predictions
Now it's time to make some predictions. Use the same data you have used for trainig the learner!
```{r predict_prerequesits, exercise.setup = "learner-solution"}
taskClassif = as_task_classif(german, id = "GermanCredit", target = "credit_risk")
lrnClassif$train(taskClassif)
```

```{r}
lrnRegr$predict(taskRegr)
```

```{r predict, exercise=TRUE, exercise.setup = "predict_prerequesits"}
"your code"
```

```{r predict-check}
checker_endpoint()
```

```{r predict-solution}
lrnClassif$predict(taskClassif)
```

## 3 Performance evaluation
Now we want to have look how well our learners perform. For now, we will evaluate the performance using a simple train/test split  ("holdout solitting"). Later in the course you will learn why this is not the preferred way and what state of the art methods there are to test performance. 

### Defining a resampling strategy
First of all we define a resampling strategy using the rsmp() function: 
```{r} 
resampling = rsmp("holdout", ratio = 2/3)
``` 

Now, in order to actually perform the resampling strategy we have defined above, we use the resample() function. We have already done this for
the regression task: 
```{r} 
resRegr = resample(taskRegr, learner = lrnRegr, resampling = resampling)
``` 

Now its your turn. Perform the resampling for the classification problem: 
```{r resampling, exercise=TRUE, exercise.setup = "predict_prerequesits"} 
resClass = "your Code"
``` 

```{r resampling-solution} 
resClass = resample(taskClassif, learner = lrnClassif, resampling = resampling)
``` 

```{r resampling-check}
checker_endpoint()
```
### Evaluation
Now we want to examine the performance of our learner on the test data. Depending on the chosen learner there are numerous performance 
measures that you can use to evaluate the performance. Generally, in mlr3 using the resample()-function, we can use the aggregate-function of the resample()-object to have a look into the performance. 

```{r} 
resRegr$aggregate()
``` 

Evaluate the performance of the classification learner using the aggregrate function! You can also experiment with different performance measures. 
```{r evaluation, exercise = TRUE, exercise.setup = "resampling-solution"} 
"your code" 
``` 
